{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Repositories\\omrtorch\n"
     ]
    }
   ],
   "source": [
    "%cd omrtorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\explo\\anaconda3\\envs\\elec491\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from omrengine import OMREngine\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from omrmodules.semantics.SystemObjects import SongFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "omrengine = OMREngine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE = os.path.join(\"samples\", \"demo_score.png\")\n",
    "sample_image = cv.imread(IMAGE)\n",
    "sample_image = OMREngine.preprocess(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1409, 1948)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppoToImage = lambda x : (np.repeat(np.moveaxis(x, 0, 2), 3, 2) * 255).astype(np.uint8)\n",
    "ShowPreProcessedImage = lambda x : Image.fromarray(ppoToImage(x))\n",
    "ShowPreProcessedImage(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_dict, object_dict = omrengine(sample_image)\n",
    "song = SongFactory(sample_image, measure_dict, object_dict).song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(omrmodules.datasets.Muscima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown color specifier: '000000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Repositories\\omrtorch\\notebooks\\Week_13.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/omrtorch/notebooks/Week_13.ipynb#ch0000008?line=1'>2</a>\u001b[0m label_dict \u001b[39m=\u001b[39m __pitch_objects__\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Repositories/omrtorch/notebooks/Week_13.ipynb#ch0000008?line=2'>3</a>\u001b[0m label_dict\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__background__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repositories/omrtorch/notebooks/Week_13.ipynb#ch0000008?line=3'>4</a>\u001b[0m omrmodules\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mMuscimaMeasures\u001b[39m.\u001b[39;49mvisualize_bboxes(sample_image, object_dict, label_dict, threshold\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Repositories\\omrtorch\\omrmodules\\datasets\\MuscimaMeasures.py:134\u001b[0m, in \u001b[0;36mvisualize_bboxes\u001b[1;34m(image, target, labels, threshold)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Repositories/omrtorch/omrmodules/datasets/MuscimaMeasures.py?line=130'>131</a>\u001b[0m   image \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(image)\n\u001b[0;32m    <a href='file:///c%3A/Repositories/omrtorch/omrmodules/datasets/MuscimaMeasures.py?line=131'>132</a>\u001b[0m sample_image \u001b[39m=\u001b[39m (image\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mByteTensor)\n\u001b[1;32m--> <a href='file:///c%3A/Repositories/omrtorch/omrmodules/datasets/MuscimaMeasures.py?line=133'>134</a>\u001b[0m sample_im_with_bounding_boxes \u001b[39m=\u001b[39m draw_bounding_boxes(sample_image, boxes_sliced, labels_list_str, colors\u001b[39m=\u001b[39;49mcolors_list, width\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, font_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Repositories/omrtorch/omrmodules/datasets/MuscimaMeasures.py?line=135'>136</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Image\u001b[39m.\u001b[39mfromarray(np\u001b[39m.\u001b[39mmoveaxis(sample_im_with_bounding_boxes\u001b[39m.\u001b[39mnumpy(), \u001b[39m0\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\explo\\anaconda3\\envs\\elec491\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\explo\\anaconda3\\envs\\elec491\\lib\\site-packages\\torchvision\\utils.py:225\u001b[0m, in \u001b[0;36mdraw_bounding_boxes\u001b[1;34m(image, boxes, labels, colors, fill, width, font, font_size)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=221'>222</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# colors specifies a single color for all boxes\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=222'>223</a>\u001b[0m     colors \u001b[39m=\u001b[39m [colors] \u001b[39m*\u001b[39m num_boxes\n\u001b[1;32m--> <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=224'>225</a>\u001b[0m colors \u001b[39m=\u001b[39m [(ImageColor\u001b[39m.\u001b[39mgetrgb(color) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(color, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m color) \u001b[39mfor\u001b[39;00m color \u001b[39min\u001b[39;00m colors]\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=226'>227</a>\u001b[0m \u001b[39m# Handle Grayscale images\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=227'>228</a>\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\explo\\anaconda3\\envs\\elec491\\lib\\site-packages\\torchvision\\utils.py:225\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=221'>222</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# colors specifies a single color for all boxes\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=222'>223</a>\u001b[0m     colors \u001b[39m=\u001b[39m [colors] \u001b[39m*\u001b[39m num_boxes\n\u001b[1;32m--> <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=224'>225</a>\u001b[0m colors \u001b[39m=\u001b[39m [(ImageColor\u001b[39m.\u001b[39;49mgetrgb(color) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(color, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m color) \u001b[39mfor\u001b[39;00m color \u001b[39min\u001b[39;00m colors]\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=226'>227</a>\u001b[0m \u001b[39m# Handle Grayscale images\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/torchvision/utils.py?line=227'>228</a>\u001b[0m \u001b[39mif\u001b[39;00m image\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\explo\\anaconda3\\envs\\elec491\\lib\\site-packages\\PIL\\ImageColor.py:118\u001b[0m, in \u001b[0;36mgetrgb\u001b[1;34m(color)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/PIL/ImageColor.py?line=115'>116</a>\u001b[0m \u001b[39mif\u001b[39;00m m:\n\u001b[0;32m    <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/PIL/ImageColor.py?line=116'>117</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mint\u001b[39m(m\u001b[39m.\u001b[39mgroup(\u001b[39m1\u001b[39m)), \u001b[39mint\u001b[39m(m\u001b[39m.\u001b[39mgroup(\u001b[39m2\u001b[39m)), \u001b[39mint\u001b[39m(m\u001b[39m.\u001b[39mgroup(\u001b[39m3\u001b[39m)), \u001b[39mint\u001b[39m(m\u001b[39m.\u001b[39mgroup(\u001b[39m4\u001b[39m)))\n\u001b[1;32m--> <a href='file:///c%3A/Users/explo/anaconda3/envs/elec491/lib/site-packages/PIL/ImageColor.py?line=117'>118</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munknown color specifier: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mrepr\u001b[39m(color)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: unknown color specifier: '000000'"
     ]
    }
   ],
   "source": [
    "from omrmodules.datasets.MuscimaObjects import __pitch_objects__\n",
    "label_dict = __pitch_objects__.copy()\n",
    "label_dict.insert(0, \"__background__\")\n",
    "omrmodules.datasets.MuscimaMeasures.visualize_bboxes(sample_image, object_dict, label_dict, threshold=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\explo\\AppData\\Local\\Temp\\ipykernel_6724\\3323202931.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(torch.tensor(sample_image))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(torch.tensor(sample_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10842ef22f3846b3472dc38517d4dd803efd693c9a70ff899e19317bf1a1c292"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('elec491')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
